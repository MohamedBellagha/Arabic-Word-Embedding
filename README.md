# Arabic-Word-Embedding
We compiled a large Arabic corpus from various sources to learn word representations. we trained and generated word vectors (embeddings) from the corpus.

# Papers
* Word2vec: Efficient Estimation of Word Representations in Vector Space (2013), T. Mikolov et al. [[pdf]](https://arxiv.org/pdf/1301.3781.pdf)
* GloVe: GloVe: Global Vectors for Word Representation (2014), J. Pennington et al. [[pdf]](https://nlp.stanford.edu/pubs/glove.pdf)
* FastText: Enriching Word Vectors with Subword Information (2016), P. Bojanowski et al. [[pdf]](https://arxiv.org/pdf/1607.04606v1.pdf)
# Set of Arabi text collections

# Preprocessing steps
Named Entity Recognition: linking of named entities using [ALP](http://arabicnlp.pro/arabic-nlp-tool/)
### example: 
* نوري_المالكي: نوري المالكي
* الحرس_الثوري: الحرس الثوري 
* محمد_علي_جعفري: محمد علي جعفري 
* الشرق_الأوسط: الشرق الأوسط
* مجلس_الجامعة_العربية : مجلس الجامعة العربية
* المملكة_العربية_السعودية : المملكة العربية السعودية

# Pre-Trained Word Vectors

| | Link | 
|---|---|
| Word2Vev|[Dawnload]() |
| FastText|[Dawnload]() |
| Glove|[Dawnload]() |
